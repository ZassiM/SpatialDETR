
*mmdetection3d/tools/test.py:
outputs = single_gpu_test(model, data_loader, args.show, args.show_dir)
    *mmdetection3d/apis/test.py
    result = model(return_loss=False, rescale=True, **data) 
        Detr3D

        forward->forward_test->simple_test
        simple_test(img_metas,img,rescale):

            1) Backbone (ResNet) + mask + Neck (FPN)
                -> images BxNxCxHxW
            img_feats = self.extract_feat(img=img, img_metas=img_metas)
                -> list of features Bx(BN/B)xCxHxW

            2) Applies head 
            bbox_pts = self.simple_test_pts (img_feats, img_metas, rescale=rescale):
                
                2.1) Uses Detr3DHead  *******
                outs = self.pts_bbox_head(img_feats, img_metas)
                    -> all_cls_scores (Tensor), all_bbox_preds (Tensor)

                2.2) Generate bboxes from bbox head predictions with NMSFreeCoder
                bbox_list = self.pts_bbox_head.get_bboxes(outs, img_metas, rescale=rescale)
                    -> list[dict]: Decoded bbox, scores and labels after NMS

                2.3) Convert detection results to a list of numpy arrays.
                bbox_results = [bbox3d2result(bboxes, scores, labels) for bboxes, scores, labels in bbox_list]
                return bbox_results

            3) Creates list of dict, with bbox and labels, and returns
            bbox_list = [dict() for i in range(len(img_metas))]
            for result_dict, pts_bbox in zip(bbox_list, bbox_pts):
                result_dict['pts_bbox'] = pts_bbox

            return bbox_list


DETAILED HEAD PART (2.1)
    -> 
outs = self.pts_bbox_head(mlvl_feats = img_feats, img_metas):
        query_embeds = self.query_embedding.weight
        
        2.1.1) Uses SpatialDETRTransformer
        hs, init_reference, inter_references = self.transformer(
            mlvl_feats,
            query_embeds,
            reg_branches=self.reg_branches if self.with_box_refine else None,
            img_metas=img_metas,
        )

        hs = hs.permute(0, 2, 1, 3)
        outputs_classes = []
        outputs_coords = []

        for lvl in range(hs.shape[0]):
            if lvl == 0:
                reference = init_reference
            else:
                reference = inter_references[lvl - 1]
            reference = inverse_sigmoid(reference)
            outputs_class = self.cls_branches[lvl](hs[lvl])
            tmp = self.reg_branches[lvl](hs[lvl])

            # TODO: check the shape of reference
            assert reference.shape[-1] == 3
            tmp[..., 0:2] += reference[..., 0:2]
            tmp[..., 0:2] = tmp[..., 0:2].sigmoid()
            tmp[..., 4:5] += reference[..., 2:3]
            tmp[..., 4:5] = tmp[..., 4:5].sigmoid()
            tmp[..., 0:1] = (tmp[..., 0:1] * (self.pc_range[3] - self.pc_range[0]) + self.pc_range[0])
            tmp[..., 1:2] = (tmp[..., 1:2] * (self.pc_range[4] - self.pc_range[1]) + self.pc_range[1])
            tmp[..., 4:5] = (tmp[..., 4:5] * (self.pc_range[5] - self.pc_range[2]) + self.pc_range[2])

            # TODO: check if using sigmoid
            outputs_coord = tmp
            outputs_classes.append(outputs_class)
            outputs_coords.append(outputs_coord)

        outputs_classes = torch.stack(outputs_classes)
        outputs_coords = torch.stack(outputs_coords)
        outs = {
            'all_cls_scores': outputs_classes,
            'all_bbox_preds': outputs_coords,
            'enc_cls_scores': None,
            'enc_bbox_preds': None, 
        }
        return outs

